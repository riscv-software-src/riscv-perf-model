:doctitle: Olympia Vector Permutation Design Document

:toc:

[[Document_Information]]
== Document Information

TODO

[[Revision_History]]
=== Revision History

[width="100%",cols="11%,11%,16%,62%",options="header",]
|===
|*Revision* |*Date*      |*Author*  |*Summary of Changes*
|0.1        | 2025.04.TODO | Sai Govardhan | Initial Vector Permutations 
Design Document
|===

[[Conventions_and_Terminology]]
=== Conventions and Terminology


[width="100%",cols="17%,83%",options="header",]
|===
|Label |Description
| VLSU | Vector Load Store Unit
| VLEN | Vector Register Length (1024 bits in Olympia)
| SEW  | Selected Element Width
| LMUL | Vector Register Group Multiplier
| ELEN | Maximum Vector Element Width
| VTA  | Vector Tail Agnostic
// TODO MORE
|===
[[Related_Documents]]
=== Related Documents

// <external documents relevant to the unit>

[width="100%",cols="25%,75%",options="header",]
|===
|*Title* |*Description*
| The RISC-V Vector ISA (v1.0) | TODO 
// | Saturn Vectors | TODO
// | The vector thesis | TODO
// Cray reference?
// Chipsalliance T1? 
// Tenstorrent Ocelot?
// Barcaelona Supercomputing Group slides?
|===

[[Notes_Open_Issues]]
=== Notes/Open Issues

// <advisories, limitations, unsolved problems>

* Note1
* Note 2

[[OVERVIEW]]
== OVERVIEW
The following is the directory structure of olympia, for reference:

```bash
.
├── arches              
├── CMakeLists.txt
├── CodingStyle.md
├── conda
├── CONTRIBUTING.md
├── CONTRIBUTORS.md
├── core                ## Consists of the vector/ directory
├── docs
├── fsl
├── layouts
├── LICENSE
├── mavis
├── mss
├── README.md
├── release
├── reports
├── sim
├── stf_lib
├── test
├── test.json
└── traces
```

We shall implement the Vector Permutation instructions in the `core/vector/`, make some modifications to the `core/InstGenerator.cpp` and run tests in the `test/core/vector/` directory. The following document lists down the instructions we have implemented, the changes we have made to the existing files and the architecture of these new vector perumute implementations.

=== Configuring the Vector Unit 

Olympia implements the Vector Unit in the `core/vector/` directory where:

 - `VLEN` is the width of the vector register statically set to 1024

 - `ELEN`, the Maximum Vector Element Width is specified based on `sew_` 
 (Selected Element Width)

Within the `core/vector/VectorConfig.hpp` file, the `VectorConfig` class is 
defined to configure the Vector Unit.

```
VectorConfig(uint32_t vl, uint32_t sew, uint32_t lmul, uint32_t vta)
```

A sample assembly instruction is:

```
vsetvli t0, a0, e32, m1   # Configure vector unit where a0 specifies the vector 
length (vl_), sew_=32, lmul_=1

```

The `vlmax_`, the maximum vector length is set to `((VLEN / sew_) * lmul_)`.

We would be using a subset of `vlmax_` by specifying the `vl_` in the vector 
configuration.

Take an example where VLEN is set to 1024, `sew_` is 32 bits and `lmul_` is 1. 
Then `vlmax_` is ((1024/32)*1) = 32. Which means that there is one logical 
Vector register is divided into 32 elements of 32 bits each.

If we set Vector Length (that we would use) `vl_` to 16, then we are using 16 
elements of 32 `vlmax_` elements we could use in the logical vector register 
file instance.

Note that the `vta_` (Vector Tail Agnostic) parameter is set to false by 
default, which indicates that it is undisturbed. When set to true, we are agnostic of the tail elements - and set it to 0s.


// <Overview of the unit, what does it do, where does it fit into Olympia
// proper, use the section below to discuss the context>

=== How are the Vector Uops generated?

We decode and determine the instructions as Vector instructions in the 
`core/decode/Decode.cpp` file.

```cpp
vector_enabled_(true),
        vector_config_(new VectorConfig(p->init_vl, p->init_sew, p->init_lmul, p->init_vta)),
```

We feed Mavis with the Vector Permutation instructions in json format as specified in the 
`mavis/json/isa_rv64v.json` and the `mavis/json/isa_rv64vf.json` files for both
the Base Vector instructions and the Vector Floating Point instructions.

The `core/vector/VectorUopGenerator.hpp` file implements the Vector Uop 
Generator. 


### Adding Support to Vector Permutation instructions

- Instruction Architecture Info:
    
    . `core/InstArchInfo.{hpp}/{cpp}`:
        .. Already has `VPERMUTE` in TargetPipe enum
        .. Need to ensure proper UopGenType for permutation, to add: 
            ... `SCALAR_MOVE`
            ... `SLIDE1UP`
            ... `SLIDE1DOWN`
            ... `SLIDEUP`
            ... `SLIDEDOWN`
            ... `RGATHER`
            ... `COMPRESS` 
            ... `WHOLE_REG_MOVE`
        
    . `mavis/json/isa_rv64v.json`:
        .. Define vector permutation instruction encodings
        .. Specify operand types and fields
    
    . `core/execute/IssueQueue.hpp`:
        .. Configure scheduler for vector permute operations
    
    . `core/execute/Execute.cpp`:
        .. Handle execution of permute operations
    
    . `core/vector/VectorConfig.hpp`:
        .. Already has basic vector config (VLEN, SEW, LMUL)
        .. May need updates for permute-specific settings
    
The files we shall be modifying: 

. `core/InstArchInfo.hpp` 
    - UopGenType to be updated to specific implementations of Vector Permutation instructions, to remove the `PERMUTE` entry

. `core/vector/VectorUopGenerator.hpp` 
    - Currently has stub for `generatePermuteUops_`

. `core/vector/VectorUopGenerator.cpp` 
    - Add implementation for specific permutation ops and replace `generatePermuteUops_`

```cpp
        uop_gen_function_map_.emplace(InstArchInfo::UopGenType::PERMUTE,
                                      &VectorUopGenerator::generatePermuteUops_);
```

. `test/core/vector/Vector_test.cpp`:
    - Add test cases for vector permutation instructions


#### List of all the Vector Permutation Instructions to be implemented:

##### Vector Scalar Move Instructions

Integer Scalar Move

    . vmv.x.s rd, vs2    # x[rd] = vs2[0]
    . vmv.s.x vd, rs1    # vd[0] = x[rs1]

Floating-Point Scalar Move

    . vfmv.f.s rd, vs2 # f[rd] = vs2[0] (rs1=0)
    . vfmv.s.f vd, rs1 # vd[0] = f[rs1] (vs2=0)


Key points:

    - Ignores LMUL and vector register groups
    - Operates even if vstart ≥ vl or vl=0
    - Handles SEW vs XLEN width differences

Micro-ops to be generated:
    
    - Since this instruction ignores the LMUL and vector register groups, we generate a single micro-op for this instruction - `SCALAR_MOVE`.
    - 
 //   - TODO REVIEW SIMPLE IMPLEMENTATION: In a simple implementation, we can permute one element per cycle - in a single cycle pipelined manner, by iterating through all the elements of the source register, check for vstart and vl, and maintain the tail agnostic policy.

    Other Handling: 
    - Note that if the vstart is greater than or equal to vl, then the micro-op is not generated and is treated as a no-op.
    - If the vl = 0, then the micro-op is generated but the destination register is not updated.
    - If the vstart is greater than or equal to vl, then the micro-op is not generated and is treated as a no-op.
    - The tail elements of the destination register are set to 0 if the vta is set to true (tail agnostic), else they are left undisurbed.

The pseudo code for the execution of the above micro-op `SCALAR_MOVE`:

```

- If we are updating a scalar destination register from the vector source register
  
    x_dest[rd] = v_src[0];

- If we are updating a vector destination register from the scalar source register
  
    v_dest[0] = x_src[rd];

TODO DOUBT: How do we enforce the rest of the v_dest elements to be set to 0 if vta is true?

##### Vector Slide Instructions
    
vslideup.vx vd, vs2, rs1, vm        # vd[i+rs1] = vs2[i]
vslideup.vi vd, vs2, uimm, vm       # vd[i+uimm] = vs2[i]

vslidedown.vx vd, vs2, rs1, vm      # vd[i] = vs2[i+rs1]
vslidedown.vi vd, vs2, uimm, vm     # vd[i] = vs2[i+uimm]

vslide1up.vx vd, vs2, rs1           # vd[0]=x[rs1], vd[i+1]=vs2[i]
vslide1up.vi vd, vs2, uimm          # vd[0]=x[uimm], vd[i+1]=vs2[i]

vslide1down.vx vd, vs2, rs1         # vd[i]=vs2[i+1], vd[vl-1]=x[rs1]
vslide1down.vi vd, vs2, uimm        # vd[i]=vs2[i+uimm], vd[vl-1]=x[uimm]

Critical behaviors:
    
    - No operation if vstart ≥ vl
    - Follows tail/mask policies
    - Source/dest register groups cannot overlap
    - OFFSET from x-reg or immediate

Micro-ops to be generated:
    
    - For the vector `SLIDEUP` micro-op, we shall iterate over each element of the source register and update the destination register based on the offset and mask. Note that the lower elements of this destination register remain unchanged.
    The computation would be as follows in pseudo code:

    ```
    for (int i = 0; i < vl; i++) {
        if (mask[i]) {
            // Note that the offset is either the register value (rs1) or the immediate value (uimm)
            dest[i + offset] = src[i];
        }
    }
    ```

    - For the vector `SLIDEDOWN` micro-op, we shall iterate over each element of the source register and update the destination register based on the offset and mask. All the upper elements fill in with zero. 
    The computation would be as follows in pseudo code:

    ```
    for (int i = 0; i < VLEN; i++) {
        if (mask[i] && i < vl) {
            dest[i] = src[i + offset];
        } else {
            dest[i] = 0;
        }
    }
    ```

    - For the vector `SLIDE1UP` micro-op, we shall update the destination register based on the offset and mask. Note that we can reuse the `SLIDEUP` micro-op for this instruction by setting the offset to 1:

    ```
    dest[0] = rs1;
    for (int i = 0; i < vl; i++) {
        if (mask[i]) {
            dest[i + 1] = src[i];
        }
    }
    ```

    - For the vector `SLIDE1DOWN` micro-op, we shall update the destination register based on the offset and mask. Note that we can reuse the `SLIDEDOWN` micro-op for this instruction by setting the offset to 1:

    ```
    for (int i = 0; i < vl; i++) {
        if (mask[i]) {
            dest[i] = src[i + 1];
        }
    }
    // The upper elements of the destination register fill in with the register value
    dest[vl - 1] = rs1;
    ```

##### Vector Register Gather

    . vrgather.vv vd, vs2, vs1, vm          # vd[i] = (vs1[i] >= VLMAX) ? 0 : vs2[vs1[i]];
    . vrgatherei16.vv vd, vs2, vs1, vm      # vd[i] = (vs1[i] >= VLMAX) ? 0 : vs2[vs1[i]];
    . vrgather.vx vd, vs2, rs1, vm          # vd[i] = (x[rs1] >= VLMAX) ? 0 : vs2[x[rs1]]
    . vrgather.vi vd, vs2, uimm, vm         # vd[i] = (uimm >= VLMAX) ? 0 : vs2[uimm]

Requirements:

    - Out-of-range indices return 0
    - No source/dest overlap allowed
    - Handles different element widths

- Micro-ops to be generated: `RGATHER`

- For instructions for vector to vector gather, we iterate over each element of the source register and update the destination register based on the index and mask. For the case where the index is out of range, we set the destination element to 0. Following is the pseudo code for the same:
    ```
    for (int i = 0; i < vl; i++) {
        if (mask[i]) {
            // Note that the index is either the register value (rs1) or the immediate value (uimm)
            int index = (rs1 != 0) ? rs1[i] : uimm;
            if (index >= VLMAX) {
                dest[i] = 0;
            } else {
                dest[i] = src[index];
            }
        }
    }
    ```
    
- For instructions with vx type gather, we iterate over each element of the source vector register, whose index is specified by the scalar register / immediate value and update the destination register based on this index and mask. For the case where the index is out of range, we set the destination element to 0. Following is the pseudo code for the same:
    ```
    for (int i = 0; i < vl; i++) {
        if (mask[i]) {
            // Note that the index is either the register value (rs1) or the immediate value (uimm)
            int index = (rs1 != 0) ? rs1[i] : uimm;
            if (index >= VLMAX) {
                dest[i] = 0;
            } else {
                dest[i] = src[index];
            }
        }
    }
    ```

##### Vector Compress

    . vcompress.vm vd, vs2, vs1     # Pack masked elements contiguously

Note that the vs1 acts as the vector mask register, which when enabled (set to 1) shall be used to contiguously pack the elements of vs2 into vd. 

Micro-ops to be generated: `COMPRESS`

The micro-op for this instruction shall iterate over each element of the source register and update the destination register based on the mask. In this implementation, we shall use a register to store the next available index in the destination register (a free pointer). 
The computation would be as follows in pseudo code:

```
int next_index = 0;
for (int i = 0; i < vl; i++) {
    if (mask[i]) {
        dest[next_index] = src[i];
        next_index++;
    }
}
```


##### Whole Vector Register Move

    . vmv1r.v v1, v2        # Copy v1=v2
    . vmv2r.v v10, v12      # Copy v10=v12; v11=v13
    . vmv4r.v v4, v8        # Copy v4=v8; v5=v9; v6=v10; v7=v11
    . vmv8r.v v0, v8        # Copy v0=v8; v1=v9; ...; v7=v15

- Micro-ops to be generated: `WHOLE_VECTOR_MOVE`

The micro-op for this instruction shall move the complete source register to the destination register, with a number of registers specified by the instruction.
We shall decode the instruction, and specify the starting index and the number of registers to be moved in the micro-op.

- Pseudo code for the micro-op:

```
for (int i = v_start; i < v_start + num_registers; i++) {
    dest[i] = src[i];
}
```

=== Overview Block Diagram

== Block Diagram of the `SCALAR_MOVE` micro-op
== Block Diagram of the `SLIDE1UP` micro-op
== Block Diagram of the `SLIDE1DOWN` micro-op
== Block Diagram of the `SLIDEUP` micro-op
== Block Diagram of the `SLIDEDOWN` micro-op
== Block Diagram of the `RGATHER` micro-op
== Block Diagram of the `COMPRESS` micro-op
== Block Diagram of the `WHOLE_REG_MOVE` micro-op


[[Functional_Description]]
== Functional Description

// <this begins the detailed description of the unit. Typically, this
// discusses each major block in a separate sub-section>
. TODO

=== Taking an example of implementing the vector move instructions

. vmv.x.s rd, vs2    # x[rd] = vs2[0]

.. We add the instruction in `mavis/json/isa_rv64v.json` file

.. Add the instruction to `core/InstArchInfo.hpp` file

```cpp
        enum class UopGenType
        {
            ...
            SCALAR_MOVE
            ...
        }
```

.. Add a new function for SCALAR_MOVE and declare it in the header.

```cpp
        InstPtr generateScalarMoveUops_();
```

.. Add the new function in the `core/vector/VectorUopGenerator.cpp` file.

```cpp

    InstPtr VectorUopGenerator::generateScalarMoveUops_()
    {
    }
```

5. Add the tests to the `test/core/vector/Vector_test.cpp` file.
    
[[Unit_Block_Diagram]]
=== Unit Block Diagram

// <Add an overview block diagram>
// image:media/image1.png[image,width=576,height=366]
// Figure 1 - Sample Figure
1. Vector Scalar Move Instruction


[[Block_Diagram_Description]]
=== Block Diagram Description


// <walk through the block diagram>

// [[Description_of_Block_B1]]
// == Description of Block <B1>

// <this section contains block level details>
. TODO

[[Operation]]
=== Operation

// <describe the low-level operation of the block>

1. Vector Scalar Move Instruction

. `vmv.x.s rd, vs2 # x[rd] = vs2[0] (vs1=0)`
- Performs its operation even if vstart ≥ vl or vl=0.
- If SEW > XLEN, the least-signi cant XLEN bits are transferred and the upper SEW-XLEN bits are ignored. 
- If SEW < XLEN, the value is sign-extended to XLEN bits

[[Interfaces]]
=== Interfaces

// <this is typically a general list of block interfaces, this changes with
// development, final design will finalize this section>
. TODO

[width="100%",cols="18%,21%,61%",options="header",]
|===
|*Name* |*C++ Type* |*Purpose/Description*
| | |
| | |
| | |
|===

[[CPP_Class_Description]]
=== C++ Class Description

// <describe the class, it’s inheritance assumptions and data structures
// used by the class
. TODO

[[Parameterization]]
=== Parameterization

// <top level parameterization, include hidden and those visible in arch
// yaml>
. TODO

[[Test_Bench_Description]]
== Test Bench Description

// <description of what is covered by the test bench, description of each
// test as appropriate
. TODO

[[Description_of_Test_1]]
=== Description of Test 1

// <discuss test 1>
. TODO

[[Description_of_Test_2]]
=== Description of Test 2

// <discuss test 2>
. TODO

[[Future_Work_or_Features]]
== Future Work or Features

// <forward looking statements>
. TODO

[[References_Citations]]
== References/Citations

// <Add references as needed>
// [1] <insert citation>
. TODO

[[Appendices]]
== Appendices

// <as needed>
. TODO

[[Appendix_1]]
=== Appendix 1

// <as needed>
. TODO
